---
title: Manual
author: Timo Hueser
date: 2021-10-29
layout: post
---

<link rel="stylesheet" href="{{site.baseurl}}/docs/assets/css/post.css">
<div id="Modal" class="modal">
 <span class="close">&times;</span>
 <img class="modal-content" id="modalImg">
 <div id="caption"></div>
</div>
<script src="{{site.baseurl}}/docs/assets/js/image_modal.js"> </script>

<center>
<span style="color:#63a31f;font-size:18px"><b>This Manual is very much work in progress, please check back in a couple of weeks if the part you are interested in is not covered yet!</b></span><br><br>
</center>

This Manual covers all the basic steps you need to take to get from the idea of using markerless tracking to 3D pose predictions ready for analysis. This obviously makes it quite a lengthy read, so feel free to skip any sections that might not be relevant to you. The blue Troubleshooting boxes can be expanded by clicking on them and will contain some hopefully helpful hints if you encounter any issues.


<hr style="border:2px solid gray">
## Designing a 3D Motion Capture Setup
Designing a good Camera Setup for Motion Capture is probably the most critical step to achieve reliable tracking and will safe you a lot of frustration while annotating, training your network and analyzing your data.\
That being said, without a proper starting point the vast number of available cameras, lenses, lighting options and possible setup configurations can be quite overwhelming.
That's why your first step should be to answer the following questions for your planned setup.<br><br>
The first set of questions will cover all the camera and lens specific decisions you'll have to make. Keep in mind that if you want to use our Acquisition Tool without any modifications you should use a camera model from our [list of supported cameras](index.html#supported_cameras).  
- <span style="color:#63a31f">**What is the size of the area my subject will move in and at what distance do I want to mount my cameras?**</span>\
 This will determine the field of view and with that the **focal length** of your lenses. You can use this handy [Calculator](https://www.lensation.de/calculator.html) to help you pick the correct values. If your setup requires lenses with a very short focal length, make sure to get lenses with as little distortion as possible.
   <img class="modalImg center" id="field_of_view" src="docs/assets/field_of_view.png" style="width:30%">
   <script>create_modal("field_of_view");</script>

- <span style="color:#63a31f">**What is the size of the smallest features you want to resolve?**</span>\
  This will determine the resolution of your camera sensor. Make sure you are able to annotate all the keypoints you want without to much difficulty at the resolution you choose.
    <img class="modalImg center" id="resolution" src="docs/assets/resolution.png" style="width:40%">
    <script>create_modal("resolution");</script>

- <span style="color:#63a31f">**What is the fastest speed my subject will move at?**</span>\
  This will determine both the minimum frame rate you need to record at and the maximum exposure time you can use. As a rough rule of thumb a framerate of 50 Hz works well for everyting that moves at human speed or lower, for fast moving subjects like monkeys or mice you'll want to go up to at least 100 Hz. If you want a more rigorous rule the [Nyquist Theorem](https://en.wikipedia.org/wiki/Nyquist_frequency) is your friend.
  <img class="modalImg center" id="fast_slow" src="docs/assets/fast_slow.png" style="width:30%">
  <script>create_modal("fast_slow");</script>

- <span style="color:#63a31f">**How long will the cables going from my cameras to the recording computer be?**</span>\
  This will determine whether GigE or USB3.0 cameras are the better choice for you. We generally recommend using USB cameras, but for distances longer than a couple of meters the ethernet based GigE cameras are the better choice.
  <img class="modalImg center" id="cable_length" src="docs/assets/cable_length.png" style="width:40%">
  <script>create_modal("cable_length");</script>


Now that the configuration of the individual cameras is out of the way, we can move on to the most important question regarding the whole setup.

<span style="color:#63a31f">**How precise does the tracking need to be for my application and how much occlusion (both by other objects in the setup and by the subject     itself) do I expect?**</span>\
This is the most important question as it determines the number of cameras you will need to use. First of all think about how many cameras fit into your budget keeping in mind that more cameras also require a more powerful recording computer. You can then determine the absolute minimum number of cameras that you need by making sure that every keypoint you want to track is visible in at least two cameras at all times, as illustrated in the sketch below. Note that this is the absolute minimum and depending on the precision you require we recommend to have every keypoint visible in at least three or four cameras at all times.
<img class="modalImg center" id="number_cameras" src="docs/assets/number_cameras.png" style="width:30%">
<script>create_modal("number_cameras");</script>

While thinking about your camera configuration try to make the angles between the cameras as wide as possible. Ideally you want to distribute your cameras as evenly as possible on a sphere around your tracking volume. The sketch below again tries to illustrate that principle.
<img class="modalImg center" id="camera_positions" src="docs/assets/camera_positions.png" style="width:70%">
<script>create_modal("camera_positions");</script>

With that all of the basic design decisions should be covered and the only thing left is a list of some of the easily overlooked but still very important things to consider:
- There are two ways to go about mounting your cameras. You can either build a very rigid and permanent mounting system, or one that is flexible and easily repositioned. Both have their obvious advantages and disadvantages and you need to decide what fits your setup structure best. But keep in mind that by going for a flexible system you will have to recalibrate your setup **EVERY** time you use it. Accurate calibrations are **the** foundation of precise 3D tracking and its hard to stress its importance enough.
- Make sure you design your setup in a way that allows you to record good calibration videos. You can check out our [example calibration recording]() to get an idea of how that looks like.  

To close of this section, here is a render of the basic structure of our 12 camera hand-tracking setup, incase you need some inspiration:

<img class="modalImg center" id="setup_render" src="docs/assets/setup_render.png" style="width:70%">
<script>create_modal("setup_render");</script>



<hr style="border:2px solid gray">
## Setting up the AcquisitionTool
With the basic setup design out of the way, the next challenge to tackle is getting all your cameras to record synchronized videos for you. Our AcquisitionTool makes this process very easy for all [FLIR machine vision cameras](https://www.flir.eu/browse/industrial/machine-vision-cameras/modelselector/).

### Hardware Requirements
- <span style="color:#63a31f">**A set of FLIR cameras:**</span> We recommend the BlackFly S model, but choose whatever fits your application best.
- <span style="color:#63a31f">**Matching GPIO cables:**</span> Those are required to hook up the external trigger, you can order them with your cameras on the FLIR website.
- <span style="color:#63a31f">**An Arduino Uno (or similar):**</span> This will be used as the source of the external trigger (And as a way to control and monitor your setup in future releases).
- <span style="color:#63a31f">**A recording computer**</span> with the following specs:
  - **A recent Nvidia GPU:** 10xx, 20xx and 30xx series cards will work. If you are using more eight cameras or more we recommend at least a 2080 or preferably a 30-series card.
  - **A decent CPU** Our tool offloads most of the work to the GPU, a modern Intel i7 or equivalent is strongly recommended.
  - **A fast SSD** Even with compression you are still writing a lot of data. We recommend SSDs with a write speed of at least 3000 MB/s.
  - **Enough USB Ports:** Make sure you have enough available USB3 ports if you are using USB cameras. FLIR sells some suitable [USB Host Controller Cards](https://www.flir.eu/products/usb-3.1-host-controller-card/). <span style="color:#bb6d24">**Caution:**</span> Some USB ports share their bandwidth, which will cause issues if you are recording at high resolutions. You can check that in the spec sheet of your motherboard.
- <span style="color:#63a31f">**A proper lighting solution:**</span> This one really depends on your setup, so we can't give any exact recommendations. But make sure you don't forget to take proper lighting into account when designing your setup. The most important factors here are even illumination from all sides and overall brightness.

### Software Installation

The first thing you will have to do is install the **FLIR Spinnaker SDK**. You can download it [here](https://www.flir.eu/products/spinnaker-sdk/). If you are running Windows make sure to download the '\*_x64.exe' found in the 'Latest Spinnaker Full SDK' directory. For Linux the '\*amd64-pkg.tar.gz' is the package you want.\
Once that is installed you can grab the [AcquisitionTool Installer](https://jarvis-mocap.github.io/jarvis-docs//2021-10-29-downloads.html) from the Downloads section. Under Windows just run the installer and follow the instructions. Under Linux you can install the AcquisitionTool by running `sudo apt install ./JARVIS-AcquisitionTool_1.0-1_amd64_2004.deb` (Make sure to replace the version numbers with the version you downloaded).
If the installation completed successfully the AcquisitionTool should now be available in your Start menu under Windows. If you are running Linux you can open it by typing `AcquisitionTool` into a terminal and pressing enter.

This is a good time to test out if everything is working as intended, before we move on to setting up synchronization with the external trigger.\
For a quick test connect at least one or two cameras to your computer, launch the AcquisitionTool and navigate to the Connection mode as shown below. You can now either connect each camera individually by clicking one of the <img height="12" src="docs/assets/add.png"> slots or simply detect all cameras with the <span style="color:#63a31f">**Auto Detect Cameras**</span> button. If that works you can then switch back to the Acquisition Mode. If your cameras are in their default mode you should be able to get them streaming by clicking the <img width="12" src="docs/assets/start.png">  button in the top left corner. If you now see live images of what all your cameras are seeing you are set to move on to the next and final setup step for the AcquisitionTool.

<img class="modalImg center" id="acquisition_test" src="docs/assets/gifs/AcquisitionSetup.gif" style="width:70%">
<script>create_modal("acquisition_test");</script>

<div class="wrap-collabsible">
  <input id="collapsible1" class="toggle" type="checkbox">
  <label for="collapsible1" class="lbl-toggle">Troubleshooting and Hints</label>
  <div class="collapsible-content">
    <div class="content-inner">
      <p>
        <ul>
        <li><b>Cameras not connecting: </b>If your cameras do not show up after clicking the Auto Detect button there's a couple of things you can do:<br>
          <ul><li>Make sure your camera is plugged into a (not shared) USB3 port (Usually the ones with the blue plastic part).</li>
          <li>Check whether you are able to access them in SpinView. If that also fails try reinstalling the Spinnaker drivers.</li>
          <li>Linux only: Make sure you did setup the group permissions and the USB buffer size correctly.</li>
          </ul>
        </li>
        <li><b>Cameras not streaming:</b> If any of your cameras are not showing an image after you start streaming this is very likely due to them being set up in a non standard acquisition mode. To make sure they have their default settings loaded you can follow the these steps:
          <ul><li>Select a camera by double clicking its name in the list in the top left corner</li>
          <li>Click the <img height="12" src="docs/assets/download.png"> arrow in the top right corner of the 'Camera Settings' Tab. This should open up the presets menu.</li>
          <li>In the menu select the 'Default' UserSet by clicking on it and press 'Load'.</li>
          <li>Try streaming again by clicking the green <img height="12" src="docs/assets/start.png"> button, it should now work for the camera you selected.</li>
          <li>Repeat those steps for all cameras that are not showing an image.</li>
          </ul>
        </li>
        <li><b>Building the Tool from source:</b> If you are planning on using the AcquisitionTool on a different Linux distribution or are interested in modifying the source code check out the <b><a href="https://github.com/JARVIS-MoCap/JARVIS-AcquisitionTool">GitHub Repo</a></b>! It has detailed instructions on how to build the tool and its dependencies yourself.</li>
        </ul>
      </p>
    </div>
  </div>
</div>
<br>


### Setting up the External Trigger
At this point you should have a recording setup that can be controlled using our AcquisitonTool and can stream video from all of your cameras. The last but very important step that is still missing is making sure all cameras record their videos perfectly in sync. To do this we use an external trigger pulse supplied by an Arduino Uno (or similar, everything that is compatible with the Arduino IDE should work with very minor modifications to the code).

The first thing you will have to do is download and install the Arduino IDE from their [website](https://www.arduino.cc/en/software). In addition you will also need to download our Arduino firmware by either clicking [here](https://github.com/JARVIS-MoCap/JARVIS-AcquisitionTool/releases/download/v1.0/Arduino_Trigger_Firmware.zip) or going to our [Downloads page](https://jarvis-mocap.github.io/jarvis-docs//2021-10-29-downloads.html).\
To install the firmware open it inside the Arduino IDE, select the correct USB port under `Tools -> Port` (the correct one should be labeled similar to `dev/ttyACM0 (Arduino Uno)`). Then simply click the upload button in the top left corner and wait for it to complete. You Arduino should be all set now!

<img class="modalImg center" id="arduino_install" src="docs/assets/gifs/ArduinoInstall.gif" style="width:70%">
<script>create_modal("arduino_install");</script>

Now comes the slightly tricky part. wiring up all the trigger cables. The exact connections you have to make depend on your exact camera model, but the general idea is always the same:
- Connect the ground (GND) pins of all cameras to one of the pins on the Arduino labeled GND.  
- Connect the trigger input (check your cameras datasheet) pin of all cameras to pin 6 of your Arduino.

For more details on how to hook up your specific camera [this guide](https://www.flir.eu/support-center/iis/machine-vision/application-note/configuring-synchronized-capture-with-multiple-cameras/) from FLIR might be helpful. Here is a very basic wiring diagram for the FLIR BlackFly S:

<img class="modalImg center" id="ArduinoWiring" src="docs/assets/ArduinoWiring.png" style="width:60%">
<script>create_modal("ArduinoWiring");</script>

Once your Arduino trigger system is all wired up you can go back to the AcquisitionTool and connect the trigger using the <img height="12" src="docs/assets/add_green.png"> button. To make the cameras use the trigger signal there are a few settings you will have to change on each camera. Again, the exact settings might vary slightly depending on your camera model. This guide shows the settings for the BlackFly S, check FLIRs documentation on your camera model if those settings don't work. Here's the step-by-step guide:
1. Select a camera by double clicking its name in the list in the top left corner
2. Make sure the cameras default settings are loaded:
  - Click the <img height="12" src="docs/assets/download.png"> arrow in the top right corner of the 'Camera Settings' Tab. This should open up the presets menu.
  - In the menu select the 'Default' UserSet by clicking on it and press 'Load'.
3. Click the <img height="12" src="docs/assets/show.png"> button to get access to all settings.
4. Here's all the settings you will have to change:
  - **Trigger Mode:** On
  - **Trigger Source:** Line3
  - **Trigger Overlap:** ReadOut
  - **Pixel Format:** BayerRG8
  - **Exposure Auto:** Off
  - **Exposure Time:** Needs to be shorter than the time between your frames (At 100 FPS the limit is 10 ms). Caution: The value is set in microseconds!

With all those settings adjusted you should now be able to record synchronized videos! To be sure it's best to do a test recording and checking if all videos have exactly the same length.

<hr style="border:2px solid gray">
## Recording Calibration Videos

#### Intrinsics Calibration

The first step to get your camera calibration files is to record one calibration video for each camera. This video will be used to compute its focal length, principal point offset and distortion
parameters. Or in simpler terms: all the camera specific parameters that we need for 3D reconstruction.

<center>
<figure class="half" style="display:flex">
<p float="left">
    <img class="modalImg" id="distortion_types" src="docs/assets/distortion_types.png" style="width:45%">
    <script>create_modal("distortion_types");</script>
    <img class="modalImg" id="camera_model" src="docs/assets/camera_model.png" style="width:30%">
    <script>create_modal("camera_model");</script>
</p>
</figure>
</center>

There are a few rules you have to follow to get the best intrinsics calibration possible:

- <span style="color:#63a31f">**Move the checkerboard along all axis (especially rotation!)**</span>\
  Make sure you do not only record frames with the checkerboard parallel to the camera (as shown in the picture on the left). Not rotating it enough makes it impossible for the calibration tool
  to estimate the focal length correctly.

<center>
  <figure class="half" style="display:flex">
    <p float="left">
      <img class="modalImg" align="center" id="Checkerboard_move_wrong" src="docs/assets/Checkerboard_move_wrong.png" style="width:24%">
      <script>create_modal("Checkerboard_move_wrong");</script>
      <img class="modalImg" align="center" id="Checkerboard_move_correct" src="docs/assets/Checkerboard_move_correct.png" style="width:25%">
      <script>create_modal("Checkerboard_move_correct");</script>
    </p>
  </figure>
</center>


- <span style="color:#63a31f">**Fill as much of the field of view with the checkerboard as possible**</span>\
  Make sure to be close enough to the camera to take advantage of the full resolution of your camera to cover at least 2/3
  of the cameras field of view. Obvioulsy it's just as important to not get so close the camera looses focus, a bigger checkerboard will help in those cases.

<center>
  <figure class="half" style="display:flex">
    <p float="left">
      <img class="modalImg" align="center" id="Checkerboard_distance_wrong" src="docs/assets/Checkerboard_distance_wrong.png" style="width:24.4%">
      <script>create_modal("Checkerboard_distance_wrong");</script>
      <img class="modalImg" align="center" id="Checkerboard_distance_correct" src="docs/assets/Checkerboard_distance_correct.png" style="width:25%">
      <script>create_modal("Checkerboard_distance_correct");</script>
    </p>
  </figure>
</center>


#### Extrinsics Calibration

The second step is to select a primary camera. This camera defines your reference frame when doing 3D reconstruction. To calibrate the extrinsic parameters you will have to record videos for all possible camera pairs that contain the primary camera. Those videos will be used to calculate the position of all secondary cameras relative to the primary camera.

<img class="modalImg center" id="extrinsics" src="docs/assets/extrinsics.png" style="width:35%">
<script>create_modal("extrinsics");</script>

The main thing to watch out for during extrinsics recordings is that both cameras have a good and unoccluded view of the checkerboard. As long as that's the case it is as simple as just waving the
board around as much as you can.\
Side note: While it is **strongly** recommended to record seperate videos for intrinsics and extrinsics it is possibly to use your extrinsic recordings for intrinsics calibration.
If you do so make sure to still follow the intrinsic calibration rules during your recordings.

<hr style="border:2px solid gray">
## Creating and Labeling Datasets
